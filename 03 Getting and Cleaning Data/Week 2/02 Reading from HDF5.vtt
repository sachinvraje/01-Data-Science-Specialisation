WEBVTT

1
00:00:00.190 --> 00:00:03.415
This lecture is about
reading data from HDF5.

2
00:00:03.415 --> 00:00:06.030
HDF5 is used for storing large data sets.

3
00:00:06.030 --> 00:00:08.580
It's also used for
storing structured data sets, and

4
00:00:08.580 --> 00:00:12.188
it supports storing a range of datatypes.

5
00:00:12.188 --> 00:00:15.450
The name HDF stands for hierarchical data
format and that's because the data is

6
00:00:15.450 --> 00:00:19.930
stored in groups which contains zero or
more data sets, along with their metadata.

7
00:00:19.930 --> 00:00:22.450
Each of these groups has a group header,
with the group name, and

8
00:00:22.450 --> 00:00:25.060
a list of attributes
corresponding to that group.

9
00:00:25.060 --> 00:00:28.380
They also have a group symbol table which
has a list of the objects in the group.

10
00:00:29.480 --> 00:00:32.800
Datasets are then multidimensional
arrays of elements along with metadata.

11
00:00:32.800 --> 00:00:38.050
They can have a header with name,
datatype, dataspace, storage layout.

12
00:00:38.050 --> 00:00:40.280
And then they also have a data array,

13
00:00:40.280 --> 00:00:44.290
which is actually sort of a data frame you
can think about it of the HDF5 element.

14
00:00:44.290 --> 00:00:47.440
If you wanna know more about the HDF5

15
00:00:47.440 --> 00:00:50.370
storage structure you can go
to the HDF5 group's website.

16
00:00:52.230 --> 00:00:55.820
The R HDF5 package is actually
installed through bioconductor.

17
00:00:55.820 --> 00:00:59.150
So the way that we're going to install
the package is we're going to source this

18
00:00:59.150 --> 00:01:02.590
URL right here, and
that will load the biocLite function.

19
00:01:02.590 --> 00:01:07.280
The first time you install a package with
biocLite, you will also have to install

20
00:01:07.280 --> 00:01:11.860
the bio base packages from Bioconductor
and so it might take a little bit.

21
00:01:11.860 --> 00:01:16.237
And so what we're gonna do is use
the biocLite command to load the R HDF5

22
00:01:16.237 --> 00:01:17.180
package.

23
00:01:17.180 --> 00:01:19.230
Then once we've downloaded the package,

24
00:01:19.230 --> 00:01:22.360
we can just load it with the same
library command that we always use.

25
00:01:23.720 --> 00:01:27.097
In this lecture we're gonna
actually create HDF5 files, and

26
00:01:27.097 --> 00:01:28.507
then interact with them.

27
00:01:28.507 --> 00:01:35.120
You can actually just use the R HDF5
file package to access data.

28
00:01:35.120 --> 00:01:39.605
And pull it out of HDF5 data sets without
having to create them yourself, but

29
00:01:39.605 --> 00:01:44.228
it's sort of easier in terms of lecturing
just to show you what it looks like when

30
00:01:44.228 --> 00:01:45.815
we create them ourselves.

31
00:01:45.815 --> 00:01:51.734
So we're gonna use the h5createFile
command to create HDF5 file set,

32
00:01:51.734 --> 00:01:54.680
which is gonna be, example.h5.

33
00:01:54.680 --> 00:01:58.640
So this lecture's gonna be
modeled very closely on

34
00:01:58.640 --> 00:02:02.770
the RHDF5 tutorial which can
be found at this website here,

35
00:02:02.770 --> 00:02:04.580
that I've linked to at
the very bottom of this slide.

36
00:02:06.985 --> 00:02:09.975
So, once we've created that HDF5 file,

37
00:02:09.975 --> 00:02:12.685
then what we can do is we can
create groups within the file.

38
00:02:12.685 --> 00:02:15.725
So we use h5createGroup.

39
00:02:15.725 --> 00:02:20.325
And so what that will do is it'll
create within this file, the group foo.

40
00:02:20.325 --> 00:02:22.645
And then we can create
another group called baa.

41
00:02:22.645 --> 00:02:28.214
And create another group That is
a sub group of a group called foobaa.

42
00:02:28.214 --> 00:02:33.180
And so what you can do then,
is you can actually see the groups and

43
00:02:33.180 --> 00:02:36.389
the names of the files that we've created.

44
00:02:36.389 --> 00:02:39.300
If you look at h5ls, so
it's like the ls command but

45
00:02:39.300 --> 00:02:42.880
it's listing out only the components
of this particular hef5 file.

46
00:02:44.420 --> 00:02:47.050
So then what we can do is
write to the specific groups.

47
00:02:47.050 --> 00:02:52.430
So for example, we can create a matrix A,
and then we can use the h5write

48
00:02:52.430 --> 00:02:56.930
command to write that matrix
to a particular group.

49
00:02:56.930 --> 00:02:59.390
So again this is the file that
we're looking at and then this

50
00:03:01.670 --> 00:03:04.920
is the group within that file, and so
we don't have to write just matrices.

51
00:03:04.920 --> 00:03:07.050
We can actually write
multidimensional arrays.

52
00:03:07.050 --> 00:03:09.920
For example,
here's a multidimensional array.

53
00:03:09.920 --> 00:03:12.420
We can actually add attributes.

54
00:03:12.420 --> 00:03:15.360
So for example,
we can give it metadata like this,

55
00:03:15.360 --> 00:03:18.990
the leader attribute,
which is sort of about the units.

56
00:03:18.990 --> 00:03:23.667
And then we can again use
the h5write command to write this

57
00:03:23.667 --> 00:03:26.760
array to a particular subgroup.

58
00:03:26.760 --> 00:03:30.850
And so again if we list out
what's going on inside this

59
00:03:30.850 --> 00:03:33.610
file now we have all
the groups that we've created.

60
00:03:33.610 --> 00:03:36.680
And also within those groups we
actually have some datasets.

61
00:03:36.680 --> 00:03:39.600
So you can see that
A is now an H5 dataset.

62
00:03:39.600 --> 00:03:41.640
And it consists of integers.

63
00:03:41.640 --> 00:03:44.700
And then there is another dataset down
here, B, which consists of floats.

64
00:03:44.700 --> 00:03:48.490
And it give you the dimensions of those
datasets that can be multidimensional.

65
00:03:52.260 --> 00:03:54.730
so we can write a data set directly.

66
00:03:54.730 --> 00:03:58.390
Also, we can write it actually a data set
to the top level group and the way that we

67
00:03:58.390 --> 00:04:01.850
do that is suppose we create a dataframe
like this, with the df command.

68
00:04:01.850 --> 00:04:05.760
So now we have this data frame up here.

69
00:04:05.760 --> 00:04:10.550
And so what we can do is we can actually
use the h5write command to write that.

70
00:04:10.550 --> 00:04:13.910
Data frame directly to
the top level group.

71
00:04:13.910 --> 00:04:17.120
So instead of passing it the group
that we're gonna send it to we

72
00:04:17.120 --> 00:04:19.460
can actually just send
it the variable name.

73
00:04:19.460 --> 00:04:24.788
So then if we list out what's going on
we now see that in the top level group,

74
00:04:24.788 --> 00:04:28.690
sort of the root group,
you see df and it's a dataset.

75
00:04:28.690 --> 00:04:31.247
And it gives you the dimensions
of the dataset and so forth.

76
00:04:33.613 --> 00:04:38.250
You can then read your written
data using the h5read command.

77
00:04:38.250 --> 00:04:41.130
So you're gonna use h5read,
you're gonna tell it what file

78
00:04:41.130 --> 00:04:45.130
you're gonna be looking in, and then for
example you can tell it to read a very

79
00:04:45.130 --> 00:04:49.340
specific data set like this
where you can do slash A.

80
00:04:49.340 --> 00:04:53.610
You can read sub data sets by just
specifying the pack like this.

81
00:04:53.610 --> 00:04:56.970
You can also read a data
set in the top level group

82
00:04:56.970 --> 00:04:59.530
by just specifying the data set name.

83
00:04:59.530 --> 00:05:02.710
And so, what you get back out
is the data that you wrote in.

84
00:05:02.710 --> 00:05:05.982
This is how you are going to read data if,
for example,

85
00:05:05.982 --> 00:05:10.125
you have a data set in a H5 file,
HDF5 file and you want to get it out.

86
00:05:10.125 --> 00:05:13.954
Another advantage of the HDF5 file
format is that you can easily read and

87
00:05:13.954 --> 00:05:18.428
write in chunks, so what we're gonna do
here actually is we're gonna write again.

88
00:05:18.428 --> 00:05:23.345
We're gonna use H5write and
we're gonna be writing to the data set, A,

89
00:05:23.345 --> 00:05:25.950
that's inside of our file.

90
00:05:25.950 --> 00:05:29.320
And so what we're gonna be doing is we're
gonna be writing the elements 12, 13, and

91
00:05:29.320 --> 00:05:33.120
14 and we can tell it, While we wanna
write into that data set and we wanna

92
00:05:33.120 --> 00:05:38.310
write it to a specific part of that data
set, so what we can do is give it indices.

93
00:05:38.310 --> 00:05:42.540
So the index file here will give you
indices for each of the dimensions.

94
00:05:42.540 --> 00:05:46.550
So the first dimension we're gonna
say write to the first three rows,

95
00:05:46.550 --> 00:05:50.780
in the first column of this dataset,
these values.

96
00:05:50.780 --> 00:05:53.870
And so if we read the dataset
after we've done that writing,

97
00:05:53.870 --> 00:05:58.560
you can see that in the first three rows
of the first column, you get 12, 13, and

98
00:05:58.560 --> 00:05:59.474
14 just like we wrote there.

99
00:05:59.474 --> 00:06:02.550
You can use a similar index command

100
00:06:02.550 --> 00:06:05.490
to read just the sub-component
of the dataset as well.

101
00:06:05.490 --> 00:06:07.920
So you can pass it an index which

102
00:06:07.920 --> 00:06:11.320
is a list that shows
the different dimensions to read.

103
00:06:11.320 --> 00:06:16.380
For example if you just wanted to read
the first three elements, the first

104
00:06:16.380 --> 00:06:20.550
three rows of the first column you could
pass this same index command to H5 read.

105
00:06:23.130 --> 00:06:25.820
So some notes further resources.

106
00:06:25.820 --> 00:06:29.510
One thing to keep in mind is that HDF5
can be used to optimize reading and

107
00:06:29.510 --> 00:06:31.560
writing from disc in R.

108
00:06:31.560 --> 00:06:35.360
This tutorial here gives a lot more
information about how to use HDF5.

109
00:06:35.360 --> 00:06:39.200
I've borrowed a lot of information for
this lecture from that tutorial.

110
00:06:39.200 --> 00:06:42.730
And the HDF5 group has a lot
of good information in general

111
00:06:42.730 --> 00:06:44.430
in using HDF5 if that's
what you're interested in.